{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4047b4e-d3b0-4e75-b968-19a1c3b4575c",
   "metadata": {},
   "source": [
    "## Computational carpentry - Group 04 - Nichelle Sequeira, Ludovica Fracassi & Emma Kappeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8371a6-5540-4e91-a100-53e15569331f",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20595b0b-877d-4230-9031-eb9a43ad1331",
   "metadata": {},
   "source": [
    "### Part A.1: Loading and Displaying Data from a CSV File\n",
    "\n",
    "In this section, we will load a CSV file containing molecular data into a Pandas DataFrame and display the first few rows for an initial inspection.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Import the Pandas Library**  \n",
    "   We start by importing the `pandas` library, which is essential for data manipulation and analysis in Python.\n",
    "\n",
    "2. **Load CSV Data into a DataFrame**  \n",
    "   We specify the path to the CSV file and use the `pd.read_csv()` function to load the data into a DataFrame.\n",
    "\n",
    "3. **Display the DataFrame**  \n",
    "   After loading the data, we will display the first few rows to inspect the structure of the dataset using the `df.head()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09c99a-8525-43c6-be8f-fb012c953594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A.1\n",
    "import pandas as pd\n",
    "\n",
    "# path to csv file\n",
    "csv_file_path = 'C:\\\\Users\\\\Nichelle Sequeira\\\\Desktop\\\\modelling-lab\\\\Project1\\\\4-Molecules.csv'\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c8876-ad5e-4d29-ab80-955c3a3cd7fa",
   "metadata": {},
   "source": [
    "### Explanation: What is this data about? (A.2)\n",
    "\n",
    "The data provided in *\"4-Molecules.csv\"*, taken from Wikipedia, appears to contain a list of all Wikipedia compound structures with their names and formulas.\n",
    "\n",
    "Each column has it's own piece of information as mentioned below;\n",
    "\n",
    "1. **row ID**: Unique identifier for each row.\n",
    "2. **Molecule**: Molecular structure, likely in SMILES format (Simplified Molecular Input Line Entry System).\n",
    "3. **Molecule name**: The chemical formula of the molecule (e.g., `H3N`, `C9H8O4`).\n",
    "4. **Mannhold LogP**: A measure of the hydrophobicity (lipophilicity) of the molecule, indicating how well it dissolves in fats versus water.\n",
    "5. **Atomic Polarizabilities**: The degree to which the distribution of electron density around atoms can be distorted.\n",
    "6. **Aromatic Atoms Count**: The number of atoms that are part of aromatic rings in the molecule.\n",
    "7. **Aromatic Bonds Count**: The number of bonds that are part of aromatic rings.\n",
    "8. **Element Count**: The total number of elements (atoms) in the molecule.\n",
    "9. **Bond Polarizabilities**: The polarizability of bonds in the molecule, indicating how bonds can be distorted.\n",
    "10. **Bond Count**: The total number of bonds in the molecule.\n",
    "11. **Ring Count**: The number of rings present in the molecular structure.\n",
    "12. **Ring Atom Count**: The number of atoms that are part of rings.\n",
    "13. **Ring Bond Count**: The number of bonds that are part of rings.\n",
    "14. **Rotatable Bonds Count**: Number of bonds that can rotate freely (influence molecular flexibility).\n",
    "15. **Rotatable Bonds Count (non terminal)**: Number of rotatable bonds excluding terminal atoms.\n",
    "16. **XLogP**: A calculation of the octanol-water partition coefficient, indicating the hydrophobicity of the molecule.\n",
    "17. **Zagreb Index**: A topological descriptor used in chemistry, related to the molecular graph's connectivity.\n",
    "18. **Molecular Formula**: The chemical formula of the molecule.\n",
    "19. **Formal Charge**: The net charge on the molecule.\n",
    "20. **Formal Charge (pos)**: The total positive formal charge on the molecule.\n",
    "21. **Formal Charge (neg)**: The total negative formal charge on the molecule.\n",
    "22. **Heavy Atoms Count**: The number of heavy atoms (all atoms except hydrogen).\n",
    "23. **Molar Mass**: The molecular mass of the molecule, in atomic mass units (amu).\n",
    "24. **SP3 Character**: Fraction of atoms with sp3 hybridization, related to the molecule’s 3D structure.\n",
    "25. **H-Bond Acceptors Count**: The number of hydrogen bond acceptors in the molecule.\n",
    "26. **H-Bond Donors Count**: The number of hydrogen bond donors in the molecule.\n",
    "27. **H-Bond Acceptors Count (Lipinski)**: Hydrogen bond acceptors as defined by Lipinski's rule of five, often used in drug design.\n",
    "28. **H-Bond Donors Count (Lipinski)**: Hydrogen bond donors as defined by Lipinski's rule of five.\n",
    "29. **TPSA**: Topological polar surface area, an indicator of the surface area of the molecule that is polar.\n",
    "30. **Balaban J Index**: A topological index used in molecular characterization (balaban’s connectivity index).\n",
    "31. **Wiener Index**: A graph-based molecular descriptor related to the molecule's connectivity and used in predicting certain chemical properties.\n",
    "32. **Randic Index**: Another graph-based topological descriptor, often used in predicting molecular activity.\n",
    "33. **Eccentric Connectivity Index**: A molecular descriptor that combines features of connectivity and eccentricity, used to predict bioactivity.\n",
    "\n",
    "Each column describes a particular molecular descriptor or property, which could be used in fields like cheminformatics, drug discovery, or materials science to model and predict the behavior of molecules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a097cc3-3dac-4fee-9af6-8c83bbc0f83e",
   "metadata": {},
   "source": [
    "### What are the datatypes in this dataframe? (A.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79cb11-a0dc-4fea-a7f2-f8df05812be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba81d2a-5fc7-4fdf-a8ea-ccab1b1e0cfe",
   "metadata": {},
   "source": [
    "The data types found in this CSV file are; strings, floats, and integers. \n",
    "\n",
    "It should be noted here that common data types include integers, floats, strings, and more. However, in programming, especially in libraries like `pandas` and `numpy`, there are more specific data types. Here one can observe data types such as `float64` and `int64`. This stands for **64-bit integer**, which means this data type can store numbers using 64 bits of memory, allowing it to hold very large integer/float values. \n",
    "\n",
    "Several columns like `Atomic Polarizabilities`, `Bond Polarizabilities`, `VABC Volume Descriptor`, `Molecular Weight`, `Topological Polar Surface Area`, and `Molar Mass` are stored as `object`. In `pandas`, the data type **`object`** refers to a **generic type** that can hold any Python object. While the most common use of `object` columns is to store **strings**, it can technically hold any type of data — including lists, dictionaries, or even numbers, if they're stored as Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d2ba5-0cb7-439a-a8b1-6014f2d91a7e",
   "metadata": {},
   "source": [
    "### How many rows & columns do we have? (A.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501218e-e673-41a2-9c02-0c3fcd57118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows and columns\n",
    "rows, columns = df.shape\n",
    "print(f'Number of rows: {rows}')\n",
    "print(f'Number of columns: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3af8e7-4ccd-4414-a9dd-675f365636a5",
   "metadata": {},
   "source": [
    "Here, we can see that the number of rows is 15166, and the number of columns is 33.  \n",
    "##### Steps\n",
    "\n",
    "1. **Get the Shape of the DataFrame**: \n",
    "   We use the `shape` attribute of the DataFrame to retrieve its dimensions. This attribute returns a tuple where the first element is the number of rows and the second element is the number of columns.\n",
    "\n",
    "   ```python\n",
    "   rows, columns = df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914edf96-6afb-4ad0-aef3-d8b5e17a60dc",
   "metadata": {},
   "source": [
    "### Is there any missing data? If yes, how much? (A.5)\n",
    "\n",
    "In this section, we will check our DataFrame for missing values as well as any invalid data entries. Understanding the quality of our dataset is essential before proceeding with any analysis.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. **Check for Missing Data**: \n",
    "   We use the `isnull()` method to identify missing values in the DataFrame. The `sum()` method counts the number of missing values in each column.\n",
    "\n",
    "   ```python\n",
    "   missing_data = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b1b19-64c7-407c-bc0e-fc7152a1155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Display the number of missing values per column\n",
    "print(missing_data[missing_data > 0])  # Shows only columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb86e4d-0189-4199-8c21-7f207f3e1f33",
   "metadata": {},
   "source": [
    "The output of this cell shows us that theoretically, there is no empty cell in our CSV file, however, after rapid inspection, one can see that certain cells contain the error message **\"#NUM!\"**. Now this error appears in excel when a formula or function contains numeric values that aren’t valid. In this version of the CSV file, this is just a string, therefore one can't tell what the value is. Therefore, the following few lines of code will determine how many such errors are found in our CSV file, and one can count these as missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb46c-1b9a-4fa7-b0af-ec18dfc1c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = 'C:\\\\Users\\\\Nichelle Sequeira\\\\Desktop\\\\modelling-lab\\\\Project1\\\\4-Molecules.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define the string to count\n",
    "target_string = '#NUM!'\n",
    "\n",
    "# Count occurrences in the entire DataFrame\n",
    "count = (data == target_string).sum().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f'The string \"{target_string}\" appears {count} times in the CSV file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade06bf3-c590-4a5f-b8b6-b861e1442d6d",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30120fe",
   "metadata": {},
   "source": [
    "### B.1\n",
    "2 Subsets were created from columns \"**Lipinski's rule of five, Mannhold LogP, Molecular weight**\". The two different conditions chosen were \n",
    "1. Lipinski's Rule of Five != 0 and Mannhold LogP <= 5.\n",
    "2. Lipinski's Rule of Five == 0 and Molecular Weight <= 500.\n",
    "Too many rows were displayed from the selection. The full tables are dowloaded in a csv file once the script is ran. Below are only displayed the 10 first rows for each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec35a5-69f6-4b04-b744-631c73df6bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/ludovica/Documents/Bachelor/BA5/Modeling Lab/4-Molecules.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df['Mannhold LogP'] = pd.to_numeric(df['Mannhold LogP'], errors='coerce')\n",
    "df['Molecular Weight'] = pd.to_numeric(df['Molecular Weight'], errors='coerce')\n",
    "df['Lipinski\\'s Rule of Five'] = pd.to_numeric(df['Lipinski\\'s Rule of Five'], errors='coerce')\n",
    "\n",
    "# Subset 1\n",
    "subset1 = df[(df['Lipinski\\'s Rule of Five'] != 0) & (df['Mannhold LogP'] <= 5)]\n",
    "\n",
    "# Subset 2\n",
    "subset2 = df[(df['Lipinski\\'s Rule of Five'] == 0) & (df['Molecular Weight'] <= 500)]\n",
    "\n",
    "# 10 first  results for Subset 1\n",
    "print(\"\\nFirst 10 Rows where Lipinski's Rule of Five != 0 and Mannhold LogP <= 5:\")\n",
    "for index, row in subset1.head(10).iterrows():\n",
    "    print(\"Row {}: Lipinski's Rule of Five = {}, Mannhold LogP = {}\".format(\n",
    "        index, row['Lipinski\\'s Rule of Five'], row['Mannhold LogP']\n",
    "    ))\n",
    "\n",
    "# 10 first  results for Subset 2\n",
    "print(\"\\nFirst 10 Rows where Lipinski's Rule of Five == 0 and Molecular Weight <= 500:\")\n",
    "for index, row in subset2.head(10).iterrows():\n",
    "    print(\"Row {}: Lipinski's Rule of Five = {}, Molecular Weight = {}\".format(\n",
    "        index, row['Lipinski\\'s Rule of Five'], row['Molecular Weight']\n",
    "    ))\n",
    "\n",
    "subset1.to_csv('lipinski_compliant_molecules.csv', index=False)\n",
    "subset2.to_csv('lipinski_violation_molecules.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b878e45-161c-42cf-ac6b-112878264f44",
   "metadata": {},
   "source": [
    "### B.2: Choice Explanation\n",
    "\n",
    "Lipinski's rule of five helps predict if a bioactive molecule such as a drug is likely to be orally active in humans, it helps identifying hydrophobic compounds that can more easily penetrate membranes. A value different from 0 indicates one of the following is being broken and the compound is not orally active. \n",
    "\n",
    "1. Molecular Weight <= 500 Da\n",
    "2. logP<=5\n",
    "3. hydrogen bond donors<=5\n",
    "4. hydrogen bond acceptors <=10.\n",
    "    \n",
    "The first subset identifies the compounds that are not orally active i.e. the Lipinski's value is different from 0, but whose problem is not the partition coefficient i.e. logP<=5.\n",
    "The second subset identifies the compounds that are predicted to be orally active i.e. Lipiski's value is 0 (no rules are broken) and the molecular weight is lower than 500 Da. This subset helped understand what the value 0 meant: wether it indicated 0 drug activity or 0 rules broken. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b6bca",
   "metadata": {},
   "source": [
    "### B.3: Statistics for **SP3 character**\n",
    "The max, min, mean and standard deviation were calculated on the data for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bc56a-88ab-4f41-8aa3-bf00e64e6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/ludovica/Documents/Bachelor/BA5/Modeling Lab/4-Molecules.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "\n",
    "df['SP3 Character'] = pd.to_numeric(df['SP3 Character'], errors='coerce')\n",
    "\n",
    "max_sp3 = df['SP3 Character'].max()\n",
    "min_sp3 = df['SP3 Character'].min()\n",
    "mean_sp3 = df['SP3 Character'].mean()\n",
    "std_sp3 = df['SP3 Character'].std()\n",
    "\n",
    "print(\"SP3 Character Statistics:\")\n",
    "print(f\"Maximum: {max_sp3}\")\n",
    "print(f\"Minimum: {min_sp3}\")\n",
    "print(f\"Mean: {mean_sp3}\")\n",
    "print(f\"Standard Deviation: {std_sp3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b786a-b064-462f-b077-1ec4b0cdb150",
   "metadata": {},
   "source": [
    "Among the 15000 circa molecules the sp3 character statistics reveal the max reached is 1, meaning the molecule is likely to have sp3 hybridized orbitals, and 0 it is not likely. The mean is 0.15 so most of the molecules are less likely to be hybridized. Finally the small standard deviation indicates that the values are not very spread around the mean, meaning many molecules have an sp3 character close to 0.148."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736ddc6-00a7-4f61-a959-c4de64e3bab9",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e84c0-0f27-4aac-a17d-4823dbf9b34b",
   "metadata": {},
   "source": [
    "### Plot 1 - Scatter showing the relationship between Molar Mass and Mannhold LogP to see how molecular weight affects hydrophobicity\n",
    "The code and plot are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50328bf7-3f3f-4ca6-a023-17a1c5d2d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\emmak\\github\\4-Molecules.csv')\n",
    "\n",
    "data['Molar Mass'] = pd.to_numeric(data['Molar Mass'], errors='coerce')\n",
    "data['Mannhold LogP'] = pd.to_numeric(data['Mannhold LogP'], errors='coerce')\n",
    "\n",
    "data = data.dropna(subset=['Molar Mass', 'Mannhold LogP'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(data['Molar Mass'], data['Mannhold LogP'], c=data['Mannhold LogP'], cmap='coolwarm', s=100)\n",
    "\n",
    "plt.title('Relationship Between Molar Mass and Mannhold LogP', fontsize=14)\n",
    "plt.xlabel('Molar Mass [g/mol]', fontsize=12)\n",
    "plt.ylabel('Mannhold LogP, i.e. Hydrophobicity', fontsize=12)\n",
    "\n",
    "plt.colorbar(scatter, label='Hydrophobicity (LogP)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b189d01-e6e9-4490-9528-a19193cc2c6e",
   "metadata": {},
   "source": [
    "The graph displayed above shows the Mannhold log(P) as a function of the molar mass of the molecules present in the csv file. The Mannhold log(P) is a measure of how hydrophobic (water-repellent) a molecule is. One the right side of the graph, there is a scale of the hydrophobicity. A dark blue colour indicates very low hydrophobicity, i.e. high hydrophilicity whereas a dark red colour indicates gigh hydrophobicity.\n",
    "\n",
    "Overall, the data suggests that as a molecule’s mass increases, its hydrophobicity also tends to increase. However, there are some interesting details to point out.\n",
    "\n",
    "Most of the molecules are found in a lower molar mass range between 0 and 2000 g/mol, with hydrophobicity values (LogP) between 0 and 10. This shows that smaller molecules can have a wide range of hydrophobic properties. Even though these smaller molecules show a variety of behaviors, there is a clear grouping of molecules with low molar mass and moderate hydrophobicity, meaning that small molecules can still be fairly hydrophobic.\n",
    "\n",
    "For larger molecules with molar masses between 3000 and 8000 g/mol, there are less data points. These molecules tend to have a more consistent hydrophobicity, mostly at 0 or 10 showing less variety. This suggests that larger molecules, while still hydrophobic, don’t vary as much in their water-repelling properties compared to smaller ones.\n",
    "\n",
    "There is one noticeable exeption with a Mannhold LogP around 50 and a molar mass close to 3000 g/mol. This molecule is extremely hydrophobic compared to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c1da8-47b9-4fb9-9dfc-f018c77af2f0",
   "metadata": {},
   "source": [
    "### Plot 2 - Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1562a7-f4c4-4335-89cc-210fe1533550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = 'C:\\\\Users\\\\Nichelle Sequeira\\\\Desktop\\\\modelling-lab\\\\Project1\\\\4-Molecules.csv'  \n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Select only numeric columns for correlation\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create the heatmap\n",
    "cax = plt.matshow(correlation_matrix, cmap='coolwarm')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.xticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "\n",
    "# Show the plot without displaying numbers\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a9c40-9178-43cd-b245-4969b4720483",
   "metadata": {},
   "source": [
    "### Correlation Heatmap Analysis\n",
    "\n",
    "#### Overview\n",
    "\n",
    "The correlation heatmap shown above represents the pairwise relationships between various molecular properties. Each square in the heatmap reflects the correlation coefficient between two variables, which can range from -1 to +1:\n",
    "- **+1**: Strong positive correlation (both variables increase together).\n",
    "- **0**: No correlation (the variables are independent).\n",
    "- **-1**: Strong negative correlation (as one variable increases, the other decreases).\n",
    "\n",
    "The heatmap uses a color gradient to display correlations, where:\n",
    "- **Red**: Positive correlation\n",
    "- **Blue**: Negative correlation\n",
    "- **White**: No correlation\n",
    "\n",
    "#### Steps Taken in the Analysis\n",
    "\n",
    "1. **Data Collection**: Various molecular descriptors were calculated for a dataset of compounds. These descriptors are features commonly used in cheminformatics for predicting molecular properties and behaviors.\n",
    "\n",
    "2. **Data Preprocessing**: The molecular data was processed to ensure that the variables were standardized, and any missing values were handled appropriately.\n",
    "\n",
    "3. **Correlation Calculation**: Pearson’s correlation coefficients were computed between all pairs of molecular descriptors. These values show how the variables are linearly related to each other.\n",
    "\n",
    "4. **Visualization**: A heatmap was created to visually represent these correlations. The color gradient helps identify both positive and negative relationships.\n",
    "\n",
    "#### Key Insights\n",
    "\n",
    "- **High Positive Correlations**:\n",
    "  - Certain descriptors such as **Hydrogen Bond Acceptors** and **Fragment Complexity** appear to have strong positive correlations, indicating that an increase in one likely leads to an increase in the other.\n",
    "\n",
    "- **Negative Correlations**:\n",
    "  - Variables like **Rotatable Bonds Count (non-terminal)** and **SP3 Character** show negative correlations with others, suggesting that as one increases, the other tends to decrease.\n",
    "\n",
    "- **Zero/Weak Correlations**:\n",
    "  - Many of the variables, such as **XLogP** and **Aromatic Atoms Count**, display weaker correlations with other descriptors, indicating that these are relatively independent factors in this dataset.\n",
    "\n",
    "- **Remark**:\n",
    "    - One should note that this distribution is symmetric with respect to the 100% correlation diagonal (going from the top left side to the bottom right)\n",
    "This visual representation is a powerful way to quickly identify relationships between multiple variables in your dataset, which can inform further analysis or modeling efforts.\n",
    "\n",
    "#### Conclusion\n",
    "The heatmap provides a clear visual guide to how molecular descriptors interact with each other. This analysis can be further used to select or eliminate certain features in predictive modeling, based on their redundancy or independence. For example, descriptors that are highly correlated (red regions) may provide similar information and could be considered for dimensionality reduction, whereas descriptors with low or no correlation might offer unique insights into molecular properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
